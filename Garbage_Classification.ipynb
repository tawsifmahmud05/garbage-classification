{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Garbage Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qdplTzzJ4w1g"
      },
      "outputs": [],
      "source": [
        "# Load Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib\n",
        "from torchvision import datasets, models\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QvKsJw647hc",
        "outputId": "c9c421a7-3ed8-4bbf-e515-497a1e62f2ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "WF5vNvht5HXD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWVLiwaz5TMT",
        "outputId": "3bad1a29-f1f3-4e30-9d36-f3c5075cee5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforms for data processing\n",
        "transformer = transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1 and numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5],    #0-1 to [-1 to 1], formula (x-mean)/std\n",
        "                         [0.5,0.5,0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "cDv2d4uG5YOi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DgDesfEB19PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = datasets.ImageFolder('/content/drive/MyDrive/Deep Learning Dataset/Garbage Classification', transformer)\n",
        "print(len(image_datasets))\n",
        "\n",
        "class_names = image_datasets.classes\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk5DSY_n5kTY",
        "outputId": "9b339647-138c-4dc3-d8ef-8ad79f980ae4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15525\n",
            "['battery', 'biological', 'brown-glass', 'cardboard', 'clothes', 'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NPu9C_uL2CHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {}\n",
        "train_idx, test_idx = train_test_split(list(range(len(image_datasets))), test_size=0.2)\n",
        "test_path = torch.utils.data.Subset(image_datasets, test_idx)\n",
        "train_set = torch.utils.data.Subset(image_datasets, train_idx)\n",
        "train_idx, val_idx = train_test_split(list(range(len(train_set))), test_size=0.25)\n",
        "val_path = torch.utils.data.Subset(image_datasets, val_idx)\n",
        "train_path = torch.utils.data.Subset(image_datasets, train_idx)\n",
        "print(len(test_path))\n",
        "print(len(train_path))\n",
        "print(len(val_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LqGERb78IRM",
        "outputId": "4d2459e2-aa79-47ce-df26-0930102a33f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3105\n",
            "9315\n",
            "3105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w5BODn6I1D2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_path,\n",
        "    batch_size = 256, shuffle = True\n",
        "    \n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_path,\n",
        "    batch_size = 256,\n",
        "    shuffle = True\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "id": "Yy7JENRMBTxJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = image_datasets.classes\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4YcGJnrCHtQ",
        "outputId": "2a4fbd51-cd7f-4e90-ee8a-f16fad4ec8b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['battery', 'biological', 'brown-glass', 'cardboard', 'clothes', 'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Network\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=12):\n",
        "        super(ConvNet,self).__init__()\n",
        "        \n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "        \n",
        "        #Input shape= (256,3,300,300)\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "        \n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "        \n",
        "        \n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "        # self.flatten()\n",
        "        \n",
        "        \n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Feed forwad function\n",
        "        \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "            \n",
        "            \n",
        "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "            \n",
        "        output=output.view(-1,32*75*75)\n",
        "        \n",
        "            \n",
        "            \n",
        "        output=self.fc(output)\n",
        "            \n",
        "        return output"
      ],
      "metadata": {
        "id": "uLuNu301D_oF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet(num_classes=12).to(device)"
      ],
      "metadata": {
        "id": "MmdvjutuEQ5Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer and Loss function\n",
        "optimizer=Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "L7CLzMt_EV7X"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20"
      ],
      "metadata": {
        "id": "ixxPni-HEZgA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fCJ9ow0F6ZiJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x, y = next(iter(train_loader))\n",
        "# print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "5pGD66PP3u7e"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x=Variable(x.cuda())"
      ],
      "metadata": {
        "id": "pYDE-CXh6b_o"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrAIYhZ16lng",
        "outputId": "dd189598-6d01-465d-dbf2-296fc798d636"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3, 150, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        \n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/9315\n",
        "    train_loss=train_loss/9315\n",
        "    \n",
        "    \n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "    \n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/3105\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy"
      ],
      "metadata": {
        "id": "5_QQq7ClEenW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qt7OhJAV7xBZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}